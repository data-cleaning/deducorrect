%\VignetteIndexEntry{deducorrect-imputation}
\documentclass[11pt, fleqn, a4paper]{article}
\usepackage[english]{babel}
\usepackage{amsmath, amssymb}
\usepackage{natbib}
\usepackage{algpseudocode}
\usepackage{algorithm}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\usepackage{threeparttable}

% stimulate latex to put multiple floats on a page.
\setcounter{topnumber}{2}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{3}
\setcounter{dbltopnumber}{2}
\renewcommand{\topfraction}{.9}
\renewcommand{\textfraction}{.1}
\renewcommand{\bottomfraction}{.75}
\renewcommand{\floatpagefraction}{.9}
\renewcommand{\dblfloatpagefraction}{.9}
\renewcommand{\dbltopfraction}{.9}
\hyphenation{time-stamp}

\usepackage{float}
 
\floatstyle{boxed}
\newfloat{Rcode}{t}{rco}
\floatname{Rcode}{Figure}


\title{Deductive imputation with the {\sf deducorrect} package}
\author{Mark van der Loo and Edwin de Jonge\\
{\small Package version \Sexpr{packageVersion("deducorrect")}}}
\begin{document}
\maketitle
\begin{abstract}



\end{abstract}

<<echo=FALSE,results=hide, keep.source=FALSE>>=
library(editrules)
library(deducorrect)
@
\maketitle

\newpage

\tableofcontents

\newpage
\section{Introduction}
The quality of raw survey data is only rarely sufficient to allow for immediate
statistical analysis. The presence of missing values (nonresponse) and
inconsistencies impedes straightforward application of standard statistical
estimation methods, and statisticians often have to spend considerable effort
to counterbalance the effect of such errors. 

There are basically two ways to take the effect of data quality issues into
account.  The first is to adapt the statistical analysis such that the effects
of these issues are taken into account. One well-documented example is to use
weighting methods which take the effect of (selective) item nonresponse into
account {\bf ref } \citep{bethlehem:2011}.  The second way is to clean up the
dataset so that missing values are completed and inconsistencies have been
repaired. The latter method has the advantage that statistical analyses of the
data becomes to a degree independent of the models used in data cleaning.
Whichever way is chosen, in most cases additional assumtions are necessary to
clean data or interpret the results of data analyses. 

Recently, a number of of near assumption-free data-cleaning methods have been
reported which rely almost purely on record consistency rules imposed {em a
priori} the data. Examples of such rules include account balances, positivity
demands on variables or forbidden value combinations in categorical data.  In a
previous paper \citep{loo:2011a} we reported on methods which use data
consistency rules and information in inconsistent records to track down and
repair typing errors, rounding errors and sign errors. The theory behind these
methods was first published by \citet{scholtus:2008, scholtus:2009} and were
implemented by us in {\sf R} package {\sf deducorrect}. Since these so-called
deductive correction methods are based on adapting values, they are not suited
for completing missing values.

In this paper, we report on an extension of the {\sf deducorrect} package which
allows for deductive imputation of missing values in either numerical or
categorical data.  By deductive imputation we mean methods which use the
observed values in a record together with consistency rules imposed on the
record to uniquely derive values where possible.  The values may be missing
because of nonresponse, or they may be deemed missing by an error localization
algorithm such as implemented in the {\sf editrules} package
\citep{jonge:2011a, loo:2011c}. 

In section \ref{sdeduimpute}, we further introduce the concept of deductive
correction and show the easyest way of imputing values with the deducorrect
package. In sections \ref{sdeductivenumerical} and \ref{sdeductivecategorical}
we expand a bit on the theory and demonstrate the use of lower-level
functionality of the package. Examples in {\sf R} code are given throughout to
help new users getting started.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Deductive imputation}
\label{sdeduimpute}
Deductive imputation relies on in-record consistency rules to derive the value
of variables which have not been completed from variables which have been
completed. These methods therefore rely on the assumption that the values used
in the derivation have been completed correctly. 



Deductive imputation methods share the important
assumption that all observed values are correct, so that imputing the missing
data can be done consistently without violating any consistency rules.


\subsection{Imputation with {\sf deduImpute}}
The simplest way to do deductive imputations with the {\sf editrules} package
is to use the {\sf deduImpute} function. For numerical data it uses two methods
(described in the next subsections) to impute as many empty values as possible.
It uses the functions {\sf solSpace} and {\sf deductiveZeros} iteratively for
each record untill no deductive improvements can be made. The return value
is an object of class {\sf deducorrect}.

Here, we will use the example from \citet{waal:2011}, Chapter 9.2. This example
uses the following edits, based on a part of the Dutch Structural Business Survey
balance account.
\begin{equation}
\begin{array}{rcl}
    x_1 + x_2      &=& x_3\\
    x_2           &=& x_4\\
    x_5 + x_6 + x_7 &=& x_8\\
    x_3 + x_8      &=& x_9\\
    x_9 - x_{10}     &=& x_{11}\\
    x_6 &\geq& 0\\
    x_7 &\geq& 0
\end{array}
\label{eqdeduImputeEdits}
\end{equation}
The rule $x_2=x_4$ may seem odd for readers not familiar to survey statistics.
However, these rules correspond to cases where respondents have to copy a
figure from one page on a paper form to another\footnote{In spite of the
availability of web-based forms, many respondents prefer paper forms.}.  
%
%
\begin{Rcode}
<<keep.source=TRUE>>=
E <- editmatrix(c(
         "x1 + x2      == x3",
         "x2           == x4",
         "x5 + x6 + x7 == x8",
         "x3 + x8      == x9",
         "x9 - x10     == x11",
         "x6 >= 0",
         "x7 >= 0"
))
dat <- data.frame(
    x1=c(145,145),
    x2=c(NA,NA),
    x3=c(155,155),
    x4=c(NA,NA),
    x5=c(NA, 86),
    x6=c(NA,NA),
    x7=c(NA,NA),
    x8=c(86,86),
    x9=c(NA,NA),
    x10=c(217,217),
    x11=c(NA,NA)
)
dat
d <- deduImpute(E,dat)
d$corrected
@
\caption{A simple example with {\sf deduImpute}. The return value is an object of class {\sf deducorrect}.}
\label{RdeduImpute}
\end{Rcode}
%
%
In Figure \ref{RdeduImpute} we give an example where the following record subject
to the edits in Eq.\ \eqref{eqdeduImputeEdits} is treated.
%
<<keep.source=FALSE,echo=FALSE>>=
dat[1,]
@
%
The record contains missing values. However, by assuming that all non-missing
values are correct, values can be derived for $x_2$, $x_4$, $x_9$ and $x_{11}$
just by considering the equality- and nonnegativity rules in the edit set.

The assumption that all missing values can be imputed consistently may not
alway be valid: the nonmissing values may be filled in erroneously, yielding
faulty derived values to impute. The reason is that {\sf deduImpute} does not
take into account all edit rules: only nonnnegativity rules and equality rules
are used to derive imputed values.

The {\sf deduImpute} function has two mechanisms to get around this. The first
is to set the option {\sf checkFeasibility=TRUE}. This causes solutions causing
new inconsistencies to be rejected. The second mechanism is to provide a
user-specified {\sf adapt} array to increase the number of variables which may
be imputed, missing or not. The {\sf adapt} array is a boolean array, stating
which variable may be changed in which record. A convenient example is to use
the {\sf adapt} array as generated by the {\sf localizeErrors} function from
the {\sf editrules} package. By specifying an {\sf adapt} array, {\sf
deduImpute} will try to fix records by imputing values which are either missing
or may be adapted according to {\sf adapt}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DEDUCTIVE IMPUTATION OF NUMERICAL DATA
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Deductive imputation of numerical data}
\label{sdeductivenumerical}

\subsection{Imputation with {\sf solSpace} and {\sf imputess}}
\subsubsection{Area of application}
The combination of functions {\sf solSpace} and {\sf imputess} can be used
to impute numerical data under linear equality restrictions:
\begin{equation}
{\bf Ax} = {\bf b}\textrm{, with } {\bf A}\in\mathbb{R}^{m\times n},
\quad{\bf x}\in\mathbb{R}^n\textrm{ and }
{\bf b}\in\mathbb{R}^m.
\label{solspaceImputation}
\end{equation}
If {\bf x} has missing values, then {\sf solSpace} returns a representation
of the linear space of imputations valid under Eqn.\
\eqref{solspaceImputation}.  The function {\sf imputess} performs the actual
imputation. It is important to note that these functions do not take into
account the presence of any inequality restrictions.

\subsubsection{How it works}
\label{ssssolSpace}
Consider a numerical record $\bf x$ with $n_{miss}$ values missing.  
The values may be missing because of nonresponse, or they may be 
deemed missing by an error localization procedure (see the next subsection).
We will
write ${\bf x}=({\bf x}_{\rm obs},{\bf x}_{\rm miss})$, with ${\bf x}_{\rm
obs}$ the observed values and ${\bf x}_{\rm miss}$ the missing ones.  Supposing
further that $\bf x$ must obey a set of equality restrictions as in Eqn.
\eqref{solspaceImputation}, we may write
${\bf A}=[{\bf A}_{\rm obs},{\bf A}_{\rm miss}]$. Consequently we have \citep{waal:2011}
\begin{equation}
    {\bf A}_{\rm miss}{\bf x}_{\bf miss} = {\bf b} - {\bf A}_{\rm obs}{\bf x}_{obs}.
\end{equation}
This gives
\begin{equation}
    {\bf x}_{\rm miss} = {\bf x}_0 + {\bf C}{\bf z},
\end{equation}
with {\bf z} an arbitrary real vector of dimension $n_{\rm miss}$ and 
${\bf x}_0$ and {\bf C} constant.

The purpose of {\sf solSpace} is to compute ${\bf x}_0$ and ${\bf C}$.
Together they determine the vector space of values available for ${\bf x}_{\sf
miss}$.  Deductive imputation can be realized by observing that if any rows of
${\bf C}$ are filled with zeros, then the sole value for the corresponding
values of ${\bf x}_{\sf miss}$ are given the corresponding values in ${\bf
x}_0$. The values of ${\bf x}_0$ and ${\bf C}$ are given by
\begin{eqnarray}
    {\bf x}_0 &=& {\bf A}^+_{\rm miss}({\bf b}-{\bf A}_{\rm obs}{\bf x}_{\rm obs})\\
    {\bf C} &=& {\bf A}^+_{\rm miss}{\bf A}_{\rm miss} - \boldsymbol{1}.
\end{eqnarray}
Here, $\boldsymbol{1}$ is the identity matrix and ${\bf A}^+_{\rm miss}$ is the
generalized inverse of {\bf A}, obeying
\begin{equation}
{\bf A}_{\rm miss}{\bf A}^+_{\rm miss}{\bf A}_{\rm miss}={\bf A}_{\rm miss}.
\end{equation}
See \citet{waal:2011} for details on the imputation method or \citet{greville:1959} for
an excellent discussion on the pseudoinverse.

\subsubsection{An example}
The {\sf solSpace} function returns the ${\bf x}_0$ and ${\bf C}$ as a
list. For example consider the first record from Figure \ref{RdeduImpute}:
<<echo=TRUE>>=
(x <- dat[1,])
@
Using the editmatrix defined in the same figure, we get:
<<keep.source=TRUE>>=
(s <- solSpace(E,x))
@
{\sf solSpace} has an extra argument {\sf adapt} which allows extra fields of
${\bf x}$ to be considered missing. An example of its use would be to determine
erroneous fields with {\sf errorLocalizer} (of the {\sf editrules} package) and
to determine the imputation space with {\sf solSpace}.

The top two and bottom two rows of {\bf C} in the example have zero
coefficients, yielding a unique solution for $x_2$, $x_3$, $x_9$ and $x_{11}$.
The unique values may be imputed with {\sf imputess}:
<<keep.source=TRUE>>=
imputess(x, s$x0, s$C)
@
If a ${\bf z}$-vector is provided as well, all values may be imputed. Here, we
choose ${\bf z}=\boldsymbol{0}$ (arbitrarily).
<<keep.source=TRUE>>=
( y <- imputess(x, s$x0, s$C, z=rep(0,ncol(s$C))) )
@
Using {\sf violatedEdits} from the editrules package, we may verify that this record satisfies every inequality
rule as well ({\sf E} as in figure \ref{RdeduImpute}).
<<keep.source=TRUE>>=
any(violatedEdits(E,y,tol=1e-8))
@

To demonstrate the use of the {\sf adapt} argument, consider the following case.
<<>>=
Ey <- editmatrix(c(
    "yt == y1 + y2 + y3",
    "y4 == 0"))
y <- c(yt=10, y1=NA, y2=3, y3=7,y4=12)
@
%Here, $y_4$ clearly violates the second rule. (A rule like this may arise when manipulating
%edit sets or pre-substituting a number of values). Since $y_4$ is not empty, {\sf solSpace}
%ignores it unless told otherwise.
<<>>=
(s <- solSpace(Ey,y))
#imputess(y,x0=s$x0,C=s$C)
@
However, using the {\sf adapt} argument, which is a logical indicator stating which
entries may be adapted, we get the following.
<<>>=
(s <- solSpace(Ey, y, adapt=c(FALSE,FALSE,FALSE,FALSE,TRUE)))
imputess(y,x0=s$x0,C=s$C)
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Imputation with {\sf deductiveZeros}}

\subsubsection{Area of application}
This method can be used to impute missing values in numerical records
subject to
\begin{eqnarray}
{\bf Ax} &=& {\bf b}\textrm{, with } {\bf A}\in\mathbb{R}^{m\times n},
\quad{\bf x}\in\mathbb{R}^n\textrm{ and }
{\bf b}\in\mathbb{R}^m
\\
{x}_j &\geq& 0 \textrm{ for at least one }j\in\{1,2,\ldots,n\}.
\label{deductiveZeroImputation}
\end{eqnarray}
Economic  survey data are often subject to account balances of the $x_t = x_1 +
x_2+\cdots x_k$. For example, $x_t$ might be the total personell cost and the
$x_i$ are costs related to permanent staff, temporary staff, externals, {\em
etc.}. It is not uncommon for respondents to leave fields open which are not
relevant to them. For example, if a company has not hired any temorary staff,
the corresponding field might be left empty while a 0 would have been
appropriate.  

In such cases, missing values are bounded from above by the sum rules while
they are bounded from below by the nonnegativity constraint. If the missing
values are ignored, and the completed values add up to the required totals,
then missing values may be uniquely imputed with 0. The function {\sf
deductiveZeros} detects such cases.

\subsubsection{How it works}
Consider again the notation of Section \ref{ssssolSpace}. We write (following
notation of \cite{waal:2011}).
\begin{equation}
{\bf b}^* = {\bf b} - {\bf A}_{\rm obs}{\bf x}_{\rm obs}.
\end{equation}
If any $b^*_l=0$, this means that the sum rule ${\bf a}_l\cdot {\bf x}=b_l$ is
obeyed if missing values are ignored. For those cases, the following properties are
checked.
\begin{itemize}
\item Each $a_{{\rm miss},lj\not=}$ has the same sign.
\item Each $a_{{\rm miss},lj}\not=0$ corresponds to a variable $x_j$ that is constrained to be nonnegative.
\end{itemize}
If these demands are obeyed, the corresponding value $x_{{\rm miss},j}$ may be imputed with 0.

\subsubsection{An example}
The function {\sf deductiveZeros} does not perform imputation itself but computes
an indicator stating which values may be imputed. As a first example consider
the following.
<<keep.source=TRUE>>=
Ey <- editmatrix(c(
    "yt == y1 + y2 + y3",
    "y1 >= 0", "y2 >= 0 ","y3 >= 0"))
y <- c(yt=10, y1=NA, y2=3, y3=7)
(I<-deductiveZeros(Ey,y))
@
The record $y$ can be imputed in one statement.
<<keep.source=TRUE>>=
y[I] <- 0
y
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DEDUCTIVE IMPUTATION OF CATEGORICAL DATA
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Deductive Imputation of categorical data}
\label{sdeductivecategorical}
\subsection{Area of application}

\section{Guidelines for combining methods}

\section{Conclusions}

\bibliographystyle{chicago}
\bibliography{deducorrect}
\end{document}
